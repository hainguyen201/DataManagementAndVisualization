version: "3.6"
services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
     
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env

  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    # container_name: datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
  
  datanode1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    # container_name: datanode
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
  nifi:
    image: apache/nifi
    container_name: nifi
    restart: unless-stopped
    ports:
      # HTTP
      - 8080:8080/tcp
      # HTTPS
      - 8443:8443/tcp
      # Remote Input Socket
      - 10000:10000/tcp
      # JVM Debugger
      - 8000:8000/tcp
      # Cluster Node Protocol
      #- 11443:11443/tcp
    environment:
      SINGLE_USER_CREDENTIALS_USERNAME: hainvadmin
      SINGLE_USER_CREDENTIALS_PASSWORD: hainvadmin@123
    volumes:
      - ./hdfs-conf:/opt/nifi/nifi-current/hdfs-conf
      # - ./nifi/database_repository:/opt/nifi/nifi-current/database_repository
      # - ./nifi/flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
      # - ./nifi/content_repository:/opt/nifi/nifi-current/content_repository
      # - ./nifi/provenance_repository:/opt/nifi/nifi-current/provenance_repository
      # - ./nifi/state:/opt/nifi/nifi-current/stategit 
      # - ./nifi_state:/opt/nifi/nifi-current/state
      # - ./nifi_db:/opt/nifi/nifi-current/database_repository
      # - ./nifi_flowfile:/opt/nifi/nifi-current/flowfile_repository
      # - ./nifi_content:/opt/nifi/nifi-current/content_repository
      # - ./nifi_provenance:/opt/nifi/nifi-current/provenance_repository  
  pyspark:
    image: jupyter/pyspark-notebook:python-3.8.8
    container_name: pyspark-notebook
    ports:
      - "8888:8888"
    volumes:
      - ./pyspark/:/home/jovyan/work/
    healthcheck:
      interval: 5s
      retries: 100 
    env_file:
      - ./hadoop.env
volumes:
  hadoop_namenode:
  hadoop_datanode:
  nifi:
  shared-workspace:
    name: "hadoop-distributed-file-system"
    driver: local